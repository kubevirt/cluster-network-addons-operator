---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-cni-linux-bridge-plugin
  namespace: {{ .Namespace }}
  labels:
    tier: node
    app: cni-linux-bridge-plugin
spec:
  selector:
    matchLabels:
      name: kube-cni-linux-bridge-plugin
  template:
    metadata:
      labels:
        name: kube-cni-linux-bridge-plugin
        tier: node
        app: cni-plugins
    spec:
{{ if .EnableSCC }}
      serviceAccountName: linux-bridge
{{ end }}
      nodeSelector:
        beta.kubernetes.io/arch: amd64
      tolerations:
        - key: node-role.kubernetes.io/master
          operator: Exists
          effect: NoSchedule
      containers:
        - name: cni-plugins
          image: {{ .LinuxBridgeImage }}
          imagePullPolicy: {{ .ImagePullPolicy }}
          command:
            - /bin/bash
            - -c
            - |
              cp -rf /usr/src/containernetworking/plugins/bin/*bridge /opt/cni/bin/
              cp -rf /usr/src/containernetworking/plugins/bin/*tuning /opt/cni/bin/
              # Some projects (e.g. openshift/console) use cnv- prefix to distinguish between
              # binaries shipped by OpenShift and those shipped by KubeVirt (D/S matters).
              # Following two lines make sure we will provide both names when needed.
              find /opt/cni/bin/cnv-bridge || ln -s /opt/cni/bin/bridge /opt/cni/bin/cnv-bridge
              find /opt/cni/bin/cnv-tuning || ln -s /opt/cni/bin/tuning /opt/cni/bin/cnv-tuning
              echo "Entering sleep... (success)"
              sleep infinity
          resources:
            requests:
              cpu: "60m"
              memory: "30Mi"
          securityContext:
            privileged: true
          volumeMounts:
            - name: cnibin
              mountPath: /opt/cni/bin
      volumes:
        - name: cnibin
          hostPath:
            path: {{ .CNIBinDir }}
