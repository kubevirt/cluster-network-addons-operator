---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-cni-linux-bridge-plugin
  namespace: {{ .Namespace }}
  labels:
    tier: node
    app: cni-linux-bridge-plugin
spec:
  selector:
    matchLabels:
      name: kube-cni-linux-bridge-plugin
  template:
    metadata:
      labels:
        name: kube-cni-linux-bridge-plugin
        tier: node
        app: cni-plugins
    spec:
{{ if .EnableSCC }}
      serviceAccountName: linux-bridge
{{ end }}
      affinity: {{ toYaml .Placement.Affinity | nindent 8 }}
      nodeSelector: {{ toYaml .Placement.NodeSelector | nindent 8 }}
      tolerations: {{ toYaml .Placement.Tolerations | nindent 8 }}
      containers:
        - name: cni-plugins
          image: {{ .LinuxBridgeImage }}
          imagePullPolicy: {{ .ImagePullPolicy }}
          command:
            - /bin/bash
            - -c
            - |
              echo 'Installing bridge and tuning CNIs'
              cp -f /usr/src/containernetworking/plugins/bin/*bridge /opt/cni/bin/
              cp -f /usr/src/containernetworking/plugins/bin/*tuning /opt/cni/bin/
              # Some projects (e.g. openshift/console) use cnv- prefix to distinguish between
              # binaries shipped by OpenShift and those shipped by KubeVirt (D/S matters).
              # Following two lines make sure we will provide both names when needed.
              find /opt/cni/bin/cnv-bridge &>/dev/null || ln -s /opt/cni/bin/bridge {{ .CNIBinDir }}/cnv-bridge
              find /opt/cni/bin/cnv-tuning &>/dev/null || ln -s /opt/cni/bin/tuning {{ .CNIBinDir }}/cnv-tuning
              echo 'Entering sleep... (success)'
              sleep infinity
          resources:
            requests:
              cpu: "60m"
              memory: "30Mi"
          securityContext:
            privileged: true
          volumeMounts:
            - name: cnibin
              mountPath: {{ .CNIBinDir }}
      volumes:
        - name: cnibin
          hostPath:
            path: {{ .CNIBinDir }}
